{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import operator\n",
    "import functools\n",
    "import random\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "np.random.seed(98765)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_unet import image_gen\n",
    "from tf_unet import unet\n",
    "from tf_unet import util\n",
    "from tf_unet.image_util import ImageDataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_EPOCHS = 100\n",
    "NEG_EPOCHS = 1\n",
    "PATCH_SIZE = 192\n",
    "MARGIN = 20\n",
    "DISCREET_MASK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomCrop(img, mask, width, height):\n",
    "    assert img.shape[0] >= width\n",
    "    assert img.shape[1] >= height\n",
    "    assert img.shape[0] == mask.shape[0]\n",
    "    assert img.shape[1] == mask.shape[1]\n",
    "    x = random.randint(0, img.shape[0] - width)\n",
    "    y = random.randint(0, img.shape[1] - height)\n",
    "    img = img[x:x+width, y:y+height]\n",
    "    mask = mask[x:x+width, y:y+height]\n",
    "    return img, mask, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def randomPatch(img, mask, width, height):\n",
    "#     img_cropped, mask_cropped, x_offset, y_offset = randomCrop(img, mask, width, height)\n",
    "    \n",
    "#     fliplr_random = np.random.random() > 0.5\n",
    "#     flipud_random = np.random.random() > 0.5\n",
    "    \n",
    "#     if fliplr_random:\n",
    "#         img_cropped = np.fliplr(img_cropped)\n",
    "#         mask_cropped = np.fliplr(mask_cropped)\n",
    "        \n",
    "#     if flipud_random:\n",
    "#         img_cropped = np.flipud(img_cropped)\n",
    "#         mask_cropped = np.flipud(mask_cropped)\n",
    "        \n",
    "#     return img_cropped, mask_cropped, x_offset, y_offset, fliplr_random, flipud_random\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation\n",
    "def do_augment_data(data, labels, flip_ud=True):\n",
    "    image = data\n",
    "    mask = labels\n",
    "    \n",
    "    flip_ud_prob = 0\n",
    "    if (flip_ud == True):\n",
    "        flip_ud_prob = 0.5\n",
    "    \n",
    "    # more aggressive augmentation:\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(flip_ud_prob),\n",
    "        iaa.Crop(percent=(0, 0.05)),\n",
    "        iaa.Affine(\n",
    "            scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "            translate_percent={\"x\": (-0.01, 0.01), \"y\": (-0.01, 0.01)},\n",
    "            rotate=(-4, 4),\n",
    "            shear=(-2, 2)\n",
    "        )\n",
    "    ], random_order = True)\n",
    "\n",
    "    seq_det = seq.to_deterministic()\n",
    "\n",
    "    image_aug = seq_det.augment_image(image)\n",
    "    mask_aug = seq_det.augment_image(mask)\n",
    "\n",
    "    if (DISCREET_MASK == True):\n",
    "        # augmentation makes some of these values not discreet, fix them here.\n",
    "        mask_aug[mask_aug > 0.5] = 1\n",
    "        mask_aug[mask_aug <= 0.5] = 0\n",
    "            \n",
    "    return image_aug, mask_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator that uses the Image data provider\n",
    "\n",
    "\n",
    "class GrayImageDataProvider(ImageDataProvider):\n",
    "    def __init__(self, search_path, a_min=None, a_max=None, data_suffix=\".png\", mask_suffix='_mask.png', shuffle_data=True, augment_data=False, flip_ud=True):\n",
    "        self.augment_data = augment_data\n",
    "        self.flip_ud = flip_ud\n",
    "        super(GrayImageDataProvider, self).__init__(search_path, a_min, a_max, data_suffix, mask_suffix, shuffle_data)\n",
    "\n",
    "    def _load_file(self, path, dtype=np.float32):\n",
    "        #im = equalize(Image.open(path).convert('L'))\n",
    "        im = Image.open(path).convert('L')\n",
    "        return np.array(im, dtype)\n",
    "    \n",
    "    def _post_process(self, data, labels):\n",
    "        if (self.augment_data):\n",
    "            data_aug, labels_aug = do_augment_data(data, labels, self.flip_ud)\n",
    "        else:\n",
    "            data_aug, labels_aug = data, labels\n",
    "        return data_aug, labels_aug;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropDataProvider(GrayImageDataProvider):\n",
    "    def __init__(self, search_path, augment_data=False, size=PATCH_SIZE, only_positive=False, crop_first=True):\n",
    "        self.size = size\n",
    "        self.only_positive = only_positive\n",
    "        self.crop_first = crop_first\n",
    "        super(CropDataProvider, self).__init__(search_path, augment_data=augment_data, flip_ud=True)\n",
    "    \n",
    "    def _post_process(self, data, labels):\n",
    "        if (self.crop_first == True):\n",
    "            while(True):\n",
    "                cropped_data, cropped_labels, x_offset, y_offset = randomCrop(data, labels, self.size, self.size)\n",
    "\n",
    "                # ignore crops with CACs in the margins\n",
    "#                 if ([0,1] in cropped_labels[0:MARGIN, 0:self.size] or\n",
    "#                     [0,1] in cropped_labels[0:self.size, 0:MARGIN] or\n",
    "#                     [0,1] in cropped_labels[-MARGIN:self.size, 0:self.size] or\n",
    "#                     [0,1] in cropped_labels[0:self.size, -MARGIN:self.size]):\n",
    "#                     continue\n",
    "\n",
    "                if(self.only_positive == True):\n",
    "                    if (not [0,1] in cropped_labels[MARGIN:-MARGIN, MARGIN:-MARGIN]):\n",
    "                        continue\n",
    "\n",
    "                return super(CropDataProvider, self)._post_process(cropped_data, cropped_labels)\n",
    "        else:\n",
    "            while(True):\n",
    "                data_aug, labels_aug = super(CropDataProvider, self)._post_process(data, labels)\n",
    "                cropped_data, cropped_labels, x_offset, y_offset = randomCrop(data_aug, labels_aug, self.size, self.size)\n",
    "\n",
    "                # ignore crops with CACs in the margins\n",
    "#                 if ([0,1] in cropped_labels[0:MARGIN, 0:self.size] or\n",
    "#                     [0,1] in cropped_labels[0:self.size, 0:MARGIN] or\n",
    "#                     [0,1] in cropped_labels[-MARGIN:self.size, 0:self.size] or\n",
    "#                     [0,1] in cropped_labels[0:self.size, -MARGIN:self.size]):\n",
    "#                     continue                \n",
    "                \n",
    "                if(self.only_positive == True):\n",
    "                    if (not [0,1] in cropped_labels[MARGIN:-MARGIN, MARGIN:-MARGIN]):\n",
    "                        continue\n",
    "                return cropped_data, cropped_labels\n",
    "    \n",
    "    def _next_data(self):\n",
    "        while(True):\n",
    "            img, label = super(CropDataProvider, self)._next_data()\n",
    "            if(self.only_positive == True and np.amax(label) == False):\n",
    "                continue\n",
    "            return img, label\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #generator = GrayImageDataProvider(\"data/training/*.png\", augment_data=True)\n",
    "# generator = CropDataProvider(\"../_data/localizer_training2/all/*.png\", augment_data=True, size=PATCH_SIZE, only_positive=False, crop_first=False)\n",
    "# #generator = CropDataProvider(\"data/training/*.png\", augment_data=True, size=PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # visualize one of the files\n",
    "\n",
    "# x_test, y_test = generator(1)\n",
    "\n",
    "# fig, ax = plt.subplots(2,1, sharey=True, figsize=(4,9))\n",
    "# ax[0].axis('off')\n",
    "# ax[1].axis('off')\n",
    "# ax[0].imshow(x_test[0,...,0], aspect=\"auto\")\n",
    "# ax[1].imshow(y_test[0,...,1], aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the augmentation\n",
    "\n",
    "# x_test, y_test = generator(1)\n",
    "\n",
    "# image = x_test[0,...,0]\n",
    "# mask = y_test[0,...,1]\n",
    "\n",
    "# image_aug, mask_aug = do_augment_data(image, mask)\n",
    "\n",
    "# fig, ax = plt.subplots(2,2, sharey=True, figsize=(8,8))\n",
    "# ax[0, 0].imshow(image, aspect=\"auto\")\n",
    "# ax[1, 0].imshow(image_aug, aspect=\"auto\")\n",
    "# ax[0, 1].imshow(mask, aspect=\"auto\")\n",
    "# ax[1, 1].imshow(mask_aug, aspect=\"auto\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "generator = CropDataProvider(\"../_data/localizer_training3/positive/*.png\", augment_data=True, size=PATCH_SIZE, only_positive=True, crop_first=True)\n",
    "net = unet.Unet(channels=generator.channels, n_class=generator.n_class, layers=3, features_root=32)\n",
    "#net = unet.Unet(channels=generator.channels, n_class=generator.n_class, layers=3, features_root=32, cost_kwargs=dict(regularizer=0.001, class_weights=[1., 200.]))\n",
    "#trainer = unet.Trainer(net, optimizer=\"momentum\", batch_size=1, opt_kwargs=dict(momentum=0.2))\n",
    "trainer = unet.Trainer(net, optimizer=\"adam\", verification_batch_size = 8)\n",
    "path = trainer.train(generator, \"./unet_trained\", training_iters=32, epochs=POS_EPOCHS, display_step=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continued training (restore, use both negative and positive values)\n",
    "\n",
    "negGenerator = CropDataProvider(\"../_data/localizer_training3/all/*.png\", augment_data=True, size=PATCH_SIZE, only_positive=False, crop_first=True)\n",
    "net = unet.Unet(channels=negGenerator.channels, n_class=negGenerator.n_class, layers=3, features_root=32)\n",
    "trainer = unet.Trainer(net, optimizer=\"adam\", verification_batch_size = 8)\n",
    "path = trainer.train(negGenerator, \"./unet_trained\", restore=True, training_iters=32, epochs=NEG_EPOCHS, display_step=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "# testGenerator = GrayImageDataProvider(\"data/10_169.png\", data_suffix=\".png\", mask_suffix=\".png\", augment_data=False)\n",
    "# #testGenerator = CropDataProvider(\"data/test/*.png\", augment_data=False, size=PATCH_SIZE, only_positive=False)\n",
    "# x_test, y_test = testGenerator(1)\n",
    "# testNet = unet.Unet(channels=testGenerator.channels, n_class=testGenerator.n_class, layers=3, features_root=32)\n",
    "# prediction = testNet.predict(\"./unet_trained/model.ckpt\", x_test)\n",
    "# mask = prediction[0,...,1] > 0.1\n",
    "# #mask = prediction[0,...,1]\n",
    "# mask = np.pad(mask, (20,20), 'constant', constant_values=(0, 0))\n",
    "\n",
    "# fig, ax = plt.subplots(1,3, sharex=True, sharey=True, figsize=(12,4))\n",
    "# plt.xlabel(\"Slice 0\")\n",
    "# ax[0].imshow(x_test[0,...,0], aspect=\"auto\")\n",
    "# ax[1].imshow(y_test[0,...,1], aspect=\"auto\")\n",
    "# ax[2].imshow(mask, aspect=\"auto\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_array(a, ref, x_offset, y_offset):\n",
    "#     result = np.zeros_like(ref)\n",
    "#     result[x_offset:a.shape[0]+x_offset, y_offset:a.shape[1]+y_offset] = a\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the model\n",
    "\n",
    "# testGenerator = GrayImageDataProvider(\"data/test_full/*.png\", data_suffix=\".png\", mask_suffix=\"_mask.png\", augment_data=False)\n",
    "# testNet = unet.Unet(channels=testGenerator.channels, n_class=testGenerator.n_class, layers=3, features_root=32)\n",
    "\n",
    "# data_test, labels_test = testGenerator(1)\n",
    "\n",
    "# uberPrediction = np.zeros((456, 456))\n",
    "\n",
    "# for i in range(200):\n",
    "#     data_cropped, labels_cropped, x_offset, y_offset, x_flip, y_flip = randomPatch(data_test[0], labels_test[0], PATCH_SIZE, PATCH_SIZE)\n",
    "#     print(x_flip, y_flip)\n",
    "#     data_cropped = np.array([data_cropped])\n",
    "#     labels_cropped = np.array([labels_cropped])\n",
    "#     prediction = testNet.predict(\"./unet_trained/model.ckpt\", data_cropped)\n",
    "#     prediction = prediction[0,...,1] > 0.5\n",
    "#     prediction = np.pad(prediction, 20, 'constant', constant_values=False)\n",
    "\n",
    "#     #unflip\n",
    "#     if x_flip == True:\n",
    "#         print('flipping lr')\n",
    "#         prediction = np.fliplr(prediction)\n",
    "#     if y_flip == True:\n",
    "#         print('flipping ud')\n",
    "#         prediction = np.flipud(prediction)\n",
    "    \n",
    "#     #uncrop\n",
    "#     prediction = pad_array(prediction, uberPrediction, x_offset, y_offset)\n",
    "\n",
    "#     uberPrediction = np.maximum(uberPrediction, prediction)\n",
    "\n",
    "# # no theory\n",
    "# oneshot_prediction = testNet.predict(\"./unet_trained/model.ckpt\", data_test)\n",
    "# oneshot_prediction = oneshot_prediction[0,...,1] > 0.5\n",
    "# oneshot_prediction = np.pad(oneshot_prediction, 20, 'constant', constant_values=False)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1,4, sharex=True, sharey=True, figsize=(16,4))\n",
    "# ax[0].imshow(data_test[0,...,0], aspect=\"auto\")\n",
    "# ax[1].imshow(labels_test[0,...,1], aspect=\"auto\")\n",
    "# ax[2].imshow(uberPrediction, aspect=\"auto\")\n",
    "# ax[3].imshow(oneshot_prediction, aspect=\"auto\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
